---
- name: Configure Storehouse1 ( no zpool Configuration)
  hosts: Storehouse1
  become: true
  vars:
    Primary_IP: 10.172.1.30
    s3_ip: 10.172.1.43
    s3_cold_ip: 10.172.1.32
  roles:
    - zfs
    - Containers
    - firewalld
    - Remote-Management
    - Service-Account
    - certbot
    - repo-netdata
    - role: netplan
      netplan_enabled: true
      netplan_config_file: /etc/netplan/01-netcfg.yaml
      netplan_renderer: networkd
      netplan_configuration:
        network:
          version: 2
          renderer: networkd
          ethernets:
              eno1:
               dhcp4: false
               dhcp6: true
               addresses:
                  - 10.172.1.30/24
                  - 10.172.1.31/24
                  - 10.172.1.32/24
                  - 10.172.1.33/24
                  - 10.172.1.34/24
                  - 10.172.1.35/24
               gateway4: 10.172.1.1
               nameservers:
                 addresses: 
                   - 10.172.1.1
                   - 10.172.16.1
              eno2:
                dhcp4: false
                dhcp6: true
                addresses:
                    - 10.172.1.36/24
                    - 10.172.1.37/24
                    - 10.172.1.38/24
                    - 10.172.1.39/24
                gateway4: 10.172.1.1
                nameservers:
                  addresses: 
                    - 10.172.1.1
                    - 10.172.16.1
              enp2s0:
                dhcp4: false
                dhcp6: true
                addresses:
                    - 10.172.1.40/24
                    - 10.172.1.41/24
                    - 10.172.1.42/24
                    - 10.172.1.43/24
                    - 10.172.1.44/24
                    - 10.172.1.45/24
                gateway4: 10.172.1.1
                nameservers:
                  addresses: 
                    - 10.172.1.1
                    - 10.172.16.1
  tasks:
    - name: Shell Task Run Timestamp
      shell: "date >> /Ansible-ran.txt"
    - name: include variables
      include_vars: ../crypt/minio_env.yaml
      # NVME Single Drive zpool
    - name: Ensure lancache-cache dataset exsists
      zfs:
        name: us-nvme-pool/lancache-cache
        state: present
        extra_zfs_properties:
          atime: off
          compression: lz4
          exec: off
          quota: 600G
          setuid: off
          logbias: throughput
          sync: standard #disabled
          redundant_metadata: most
    - name: Ensure lancache-logs dataset exsists
      zfs:
        name: us-nvme-pool/lancache-logs
        state: present
        extra_zfs_properties:
          atime: off
          compression: lz4
          exec: off
          quota: 10G
          setuid: off
          logbias: latency
          sync: standard 
    - name: Ensure USDB dataset exsists
      zfs:
        name: us-nvme-pool/USDB
        state: present
        extra_zfs_properties:
          atime: off
          compression: lz4
          exec: off
          quota: 50G
          setuid: off
          logbias: latency
          sync: standard     
    - name: Ensure s3-nvme dataset exsists
      zfs:
        name: us-nvme-pool/s3-nvme
        state: present
        extra_zfs_properties:
          atime: off
          compression: off
          exec: off
          quota: 100G
          setuid: off
          logbias: latency
          sync: standard 
      # Mirror Mirror Pool
    - name: Ensure USDB-bkup dataset exsists On Mirror
      zfs:
        name: Mirror/USDB-bkup
        state: present
        extra_zfs_properties:
          atime: on
          compression: lz4
          exec: off
          refquota: 50G
          setuid: off
          logbias: latency
          sync: standard
    - name: Ensure s3-nvme-bkup dataset exsists On Mirror
      zfs:
        name: Mirror/s3-nvme-bkup
        state: present
        extra_zfs_properties:
          atime: on
          compression: lz4
          exec: off
          refquota: 100G
          setuid: off
          logbias: latency
          sync: standard
    - name: Ensure s3 dataset exsists On Mirror
      zfs:
        name: Mirror/s3
        state: present
        extra_zfs_properties:
          atime: on
          compression: lz4
          exec: off
          refquota: 500G
          setuid: off
          logbias: latency
          sync: standard
    - name: Ensure Proxmox Backup exsists On Mirror
      zfs:
        name: Mirror/Proxmox
        state: present
        extra_zfs_properties:
          atime: on
          compression: lz4
          exec: off
          refquota: 700G
          setuid: off
          logbias: throughput
          sync: standard
    # lancache Containers
    - name: lancache monolithic Container
      docker_container:
        name: monolithic-cache
        image: lancachenet/monolithic:latest
        pull: yes
        state: started
        restart_policy: unless-stopped
        privileged: no
        keep_volumes: yes
        published_ports:
          - "10.172.1.41:80:80/tcp"
        capabilities:
          - cap_net_bind_service
        memory: "4608m"
        env:
          CACHE_MEM_SIZE: "4096m"
          CACHE_DISK_SIZE: "600000m"
          UPSTREAM_DNS: "1.1.1.1 8.8.8.8"
        volumes:
          - "/us-nvme-pool/lancache-cache:/data/cache"
          - "/us-nvme-pool/lancache-logs:/data/logs"
    - name: lancache https proxy Container
      docker_container:
        name: sniproxy
        image: lancachenet/sniproxy:latest
        pull: yes
        state: started
        restart_policy: unless-stopped
        privileged: no
        published_ports:
          - "10.172.1.41:443:443/tcp"
        capabilities:
          - cap_net_bind_service
        memory: "512m"
        env:
          UPSTREAM_DNS: "1.1.1.1 8.8.8.8"
    #Install MinIo
    - name: get minio binary
      get_url:
        url: https://dl.min.io/server/minio/release/linux-amd64/minio
        dest: /usr/bin/minio
        force: yes
        group: "root"
        owner: "root"
        mode: "0751"
    - name: Set cap_net_bind_service=+ep /usr/bin/minio
      capabilities:
        path: /usr/bin/minio
        capability: cap_net_bind_service=+ep
        state: present       
    # MinIO User Accounts 
    - name: MinIO Fast
      user:
        name: "s3-fast"
        comment: MinIO on nvme
        password_lock: yes
        append: yes
        create_home: true
        system: yes
        shell: "/bin/bash"
    - name: MinIO SLow
      user:
        name: "s3-slow"
        comment: MinIO on Mirror
        password_lock: yes
        append: yes
        create_home: true
        system: yes
        shell: "/bin/bash"
    - name: Folder Mounts MinIO Fast
      file:
        path: "/us-nvme-pool/s3-nvme"
        state: directory
        recurse: yes
        owner: "s3-fast"
        group: "s3-fast"
    - name: Folder Mounts MinIO slow
      file:
        path: "/Mirror/s3"
        state: directory
        recurse: yes
        owner: "s3-slow"
        group: "s3-slow"
    #SSL certs
    - name: Folder .minio  MinIO Fast
      file:
        path: "/home/s3-fast/.minio"
        state: directory
        recurse: yes
        owner: "s3-fast"
        group: "s3-fast"
    - name: Folder .minio  MinIO Fast
      file:
        path: "/home/s3-fast/.minio/certs"
        state: directory
        recurse: yes
        owner: "s3-fast"
        group: "s3-fast"
    - name: Folder .minio  MinIO slow
      file:
        path: "/home/s3-slow/.minio"
        state: directory
        recurse: yes
        owner: "s3-slow"
        group: "s3-slow"
    - name: Folder .minio  MinIO slow
      file:
        path: "/home/s3-slow/.minio/certs"
        state: directory
        recurse: yes
        owner: "s3-slow"
        group: "s3-slow"
    # move from letsencript
    - name: Copy a fullchain file 
      copy:
        src: /etc/letsencrypt/live/s3-cold.core.ghostlink.net/fullchain.pem
        dest: /home/s3-slow/.minio/certs/public.crt
        owner: "s3-slow"
        group: "s3-slow"
        remote_src: yes
    - name: Copy a priv key file 
      copy:
        src: /etc/letsencrypt/live/s3-cold.core.ghostlink.net/privkey.pem
        dest: /home/s3-slow/.minio/certs/private.key
        owner: "s3-slow"
        group: "s3-slow"
        remote_src: yes
    - name: Copy a fullchain file 
      copy:
        src: /etc/letsencrypt/live/s3.core.ghostlink.net/fullchain.pem
        dest: /home/s3-fast/.minio/certs/public.crt
        owner: "s3-fast"
        group: "s3-fast"
        remote_src: yes
    - name: Copy a priv key file 
      copy:
        src: /etc/letsencrypt/live/s3.core.ghostlink.net/privkey.pem
        dest: /home/s3-fast/.minio/certs/private.key
        owner: "s3-fast"
        group: "s3-fast"
        remote_src: yes
    # firewall dependencys
    - firewalld:
        port: "443/tcp"
        permanent: yes
        state: enabled
    - firewalld:
        service: https
        permanent: yes
        state: enabled
    # env     
    - name: Create minio-slow env removing old
      file:
        path: "/home/s3-slow/.env"
        state: absent
    - name: Create minio-slow env
      file:
        path: "/home/s3-slow/.env"
        owner: s3-slow
        group: s3-slow
        mode: '0664'
        state: touch
    - name: Mash env file
      lineinfile:
        path: "/home/s3-slow/.env"
        line: "MINIO_ACCESS_KEY={{ Server_Access_Key_mirror }}\nMINIO_SECRET_KEY={{ Server_Secret_Key_mirror }}\nMINIO_REGION_NAME=StoreHouse-mirror"
    - name: Create  minio-fast env removing old
      file:
        path: "/home/s3-fast/.env"
        state: absent
    - name: Create minio-fast env
      file:
        path: "/home/s3-fast/.env"
        owner: s3-fast
        group: s3-fast
        mode: '0664'
        state: touch
    - name: Mash env file
      lineinfile:
        path: "/home/s3-fast/.env"
        line: "MINIO_ACCESS_KEY={{ Server_Access_Key_nvme  }}\nMINIO_SECRET_KEY={{ Server_Secret_Key_nvme }}\nMINIO_REGION_NAME=StoreHouse-nvme"
      # systemd minio    
    - name: Create minio-slow unitfile removing old
      file:
        path: "/etc/systemd/system/minio-slow.service"
        state: absent
    - name: Create minio-slow unitfile
      file:
        path: "/etc/systemd/system/minio-slow.service"
        owner: root
        group: root
        mode: '0664'
        state: touch
    - name: Mash Unit file
      lineinfile:
        path: "/etc/systemd/system/minio-slow.service"
        line: "[Unit]\nDescription=minio s3 server\nAfter=network-online.target\nWants=network-online.target\n[Service]\nType=simple\nExecStart=/usr/bin/minio server --address \"{{ s3_cold_ip }}:443\" --certs-dir=/home/s3-slow/.minio/certs/ /Mirror/s3\nUser=s3-slow\nGroup=s3-slow\nEnvironmentFile=/home/s3-slow/.env\n[Install]\nWantedBy=multi-user.target"
    - name: enable service minio-slow.service and ensure it is not masked
      ignore_errors: no
      systemd:
        name: minio-slow
        daemon_reload: yes
        state: restarted
        enabled: yes
        masked: no
    - name: Create minio-fast unitfile removing old 
      file:
        path: "/etc/systemd/system/minio-fast.service"
        state: absent
    - name: Create minio-fast unitfile
      file:
        path: "/etc/systemd/system/minio-fast.service"
        owner: root
        group: root
        mode: '0664'
        state: touch
    - name: Mash Unit file
      lineinfile:
        path: "/etc/systemd/system/minio-fast.service"
        line: "[Unit]\nDescription=minio s3 server\nAfter=network-online.target\nWants=network-online.target\n[Service]\nType=simple\nExecStart=/usr/bin/minio server --address \"{{ s3_ip }}:443\" --certs-dir=/home/s3-fast/.minio/certs/ /us-nvme-pool/s3-nvme\nUser=s3-fast\nGroup=s3-fast\nEnvironmentFile=/home/s3-fast/.env\n[Install]\nWantedBy=multi-user.target"
    - name: enable service minio-fast.service and ensure it is not masked
      ignore_errors: no
      systemd:
        name: minio-fast
        daemon_reload: yes
        state: restarted
        enabled: yes
        masked: no